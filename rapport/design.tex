\section{Designing a memory efficient regular expression engine}
\label{sec:design}

In the following we will describe our design and the alternatives we
considered. First we will have some general reflections on the overall
design which we will build on in a discussion about alternatives and
solutions. At the end of this section we will have described our
chosen solution and the individual components.

\subsection{Architecture}

In this thesis we will build a general framework for matching regular
expressions with strings. Our vision is a flexible architecture where
the user is in control. Regular expression matching is a sequence of
operations, where not all operations are needed at all times. This
leads to the idea that we can split the regular expression engine into
several dedicated parts. This can be demonstrated by considering the
tasks of simple acceptance and extractions of groupings, the first
only reports if a string matches a regular expression and the latter
will also report on any groupings. By pulling this functionality out
of the regular expression engine, we make the job of reporting simple
acceptance simpler.

Before moving on, there are some prerequisites that must be
discussed. This leads us to a discussion on possible mechanisms that
would allow us to separate each task. We require several things: a
mechanism to construct a NFA, a means of generate a syntax tree and a
compact means of passing on the current state of the match process.


\subsubsection{Constructing an NFA}
In this thesis we have chosen to use Thompsons method of constructing
NFAs. The NFAs constructed in this manner exhibit desirable
properties: All states has no more than two outgoing transitions and
the number of states grows linear in the size of the regular
expression. Typically you would take this one step further and in some
way build a DFA from the NFA, since these has much better traversal
properties. We will not be doing this; the worst-case behavior of
building a DFA is exponential both in time and space, as we will see
in the evaluation section and they will generally not have two
outgoing edges per state. Particularly the last part about the
outgoing edges makes us chose the NFA over the DFA, the worst-case
behavior will in practice very rarely happen.

\subsubsection{Dubè and Feeley}
One way of communicating the current state of the match process, would
be to send the whole parse tree. An efficient algorithm for parsing
with regular expressions is presented by Dubè and Feeley in their
paper from 2000 \cite{Dube2000}. The algorithm produces a parse tree,
describing how string $w$ matches regular expression $r$. For a fixed
regular expression the algorithm runs in time linear in the size of
$w$.

To build the parse tree, we first construct a NFA corresponding to
$r$. The article specifies a method for construction, but this can be
any NFA constructed so that the number of states is linear in the
length of $r$, this includes those constructed with Thompsons
method\cite{Thompson1968}. This restriction ensures the run time
complexity. Until this point there is no difference from a standard
NFA, but Dubé and Feeley then add strings to some of the edges. These
strings are outputted whenever the associated edge is followed. When
the outputted strings are then read in order they form a parse tree.

The idea of having output attached to edges is further developed in
the paper \cite{Henglein2010}. The parse trees Dubè and Feeleys method
yields are rather verbose and can be more compactly represented:
Whenever a node has more than one outgoing edge, a string is added to
the edge, containing just enough information to decide which edge was
taken.

NFA simulation with Dubè and Feeleys algorithm takes up takes up space
linear in the regular expression. We need to allocate space for the
NFA and for a list of active states, both use space linear in the
regular expression.

Added to this is the storage requirements for output, which will take
up space linear in the product of the size of the regular expression
and the input string: For each input character we can at most take
every transition once. This is the same asymptotic behavior as the
compacted version from Henglein and Nielsens paper.

So the total memory cost, counting both the simulation phase and the
saving the output, is linear in the product of the size of the regular
expression and the input string.


\subsubsection{Bit-values and mixed bit-values}

Henglein and Nielsen introduce the notion of bit-values in
\cite{Henglein2010}. A bit-value is a compact representation of how a
string matches a regular expression. In itself it is just a sequence
of \texttt{0}s and \texttt{1}s and has no meaning without the
associated regular expression. The actual bit-value for a string is
not unique and will depend on the choice of regular expression. If the
regular expression is ambiguous and matches the string in more than
one way, there will also be more than one sequence, or bit-value, for
this combination of string and regular expression.

However, if we rely on the property of a Thompsons NFA, that no state
has more than two outgoing transitions, we have a perfect mapping for
the bit-values. Instead of mapping syntax tree constructors to
bit-values, we will map the outgoing transitions in split-states to
bit-values. Each time we are faced with a choice when traversing the
NFA, we will record that choice with a bit-value. This will enable us
to recreate the exact path through the NFA. See also \cite{Dube2000}.

For reasons we will discuss later we will introduce the notion of
mixed bit-values in this thesis. When simulating the NFA we will
simultaneously be creating many bit-values which may or may not end up
in an actual match. These individual bit-values will be referred to as
a channel. Mixed bit-values is the set of all these channels and they
are simply a way of talking about multiple paths through the NFA.

\subsubsection{Splitting up the workload}
We have now introduced the bit-values. The bit-values enables us to
split up the work in several tasks. 
\begin{itemize}
\item The first task will be to create the mixed bit-values describing
  the paths the Thompson matching algorithm takes through the NFA. The
  first task will need the regular expression to form the NFA and the
  string for the matching. Note that there is no need to store the
  whole string, the matching processes the characters in the input
  string in a streaming fashion.
\item The next and also last step in a simple acceptance match, would
  be to check the mixed bit-values for a match. Simply scan the
  bit-values for acceptance. 
\item In extracting the values of groupings, we would need more
  tasks. We could form a task that cuts away unneeded parts of the
  parse tree. Only the parts concerned with contents of the groupings
  would be needed to actually extract the values. To do this we would
  require the regular expression to form an NFA annotated so that we
  could recognize the relevant parts of the syntax tree.
\item We have a stream of mixed bit-values. It would be necessary at
  some point to extract the channel that makes up the actual match, if
  there is one. This can not be done in a streaming fashion. When
  first encountering a new channel, we need to know whether or not it
  has a match. The only way to know this is to read the whole stream
  of mixed bit-values. This task would only need the stream of mixed
  bit-values, it has no need for the regular expression.
\item The last step in extracting the values of the groupings would be
  to output the actual values in some format. To do this we would
  require the bit-values from the match and the regular
  expression. The regular expression is so that we can form an NFA
  annotated with the positions of the groupings. 
\end{itemize}


\subsubsection{Solutions}

There are two main methods of realizing this design. We can make the
tasks be small separate programs that communicate through pipes or we
can make one program where the tasks will be processes that
communicate through some inter-process communication model. The
separate programs model has the advantage of being simpler, in that
the communication framework is already in place, we would not have to
worry about synchronization and such. The processes model would
probably have the advantage of being much faster in communicating and
a generally lower overhead, all according to which model for
inter-process communication was chosen. We have chosen the separate
programs model, because of the ease with which you can combine the
separate programs and the much simpler communication model. This also
opens up for the possibility to store the output from one task for
later use, or perhaps even piping the output to a completely different
system with for example \texttt{netcat}. %\todo{jan: naevner du mulighederne nogle steder?}

The tasks will in some sense be projections performed on the mixed
bit-values and the bit-values. The programs will therefore be called
filters. 


%% \todo[inline]{What is a filter? The whole deal with the pipes!}
%% \todo[inline]{Pros and cons to filters vs other solutions}

We present the overall architecture in figure
\vref{fig:architecture}. In the first program we have the matcher,
this program will take the regular expression as an argument and have
the string piped in and will output the mixed bit-values that
comprises the match. The second program will take the mixed bit-values
from the first and filter out those mixed bit-values relevant to the
capturing groupings only. The third program takes mixed bit-values and
filters out the bit-values relevant to the actual match, if there is
no match, the output will be the empty string. The fourth program
takes bit-values and constructs the string that was matched with those
bit-values. If you rewrite the regular expression so that it only
consists of the capturing groups and adjust your bit-values
accordingly, this will result in the capturing groups being
outputted. We have put in a fifth, hypothetical, program in the design to signal that
you could have more filters and place them anywhere in the chain (though there are some common sense limitations)
\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{design/architecture.pdf}
  \caption{Architecture outline}
  \label{fig:architecture}
\end{figure}


%% \todo[inline]{
%% Fleksibel arkitektur (skal tales om sent, det er en implementeringsting):
%%  - hvorfor som unix utility. Plus: nemt at søtte sammen on the fly,
%%  kan nemt serialisiere og transmittere output
%%  - andre alternativer: in-process components. Hvad er drawback: fx
%%  mere bøvlet at sætte sammen on the fly. Hvad er plus: hurtigere
%%  kommunikation mellem komponenter. Reuse af NFA.
 
%% Mixed-bit-values:
%%  Motivation: ?? (kompression?)
%%  Valgmuligheder: alternativer (IKKE IMPLEMENTATION)
%%  Valg
%% }

\subsection{Protocol specification}
\label{sec:protocol_spec}

%\todo[inline]{Introduce the mixed bit-values term.}

In this section we will define a protocol that can communicate
information between our programs. The information consists of the
mixed bit-values generated by the NFA simulator and the filters.

\begin{itemize}
\item The protocol should enable us to recreate paths taken through an
  NFA.
\item The protocol should be one-way. Information can only flow in one
  direction.
\item This protocol is intended to communicate between programs where
  we can expect perfect synchronization and unambiguity. For example
  will it not be necessary to include any error correction. 
%\item Similarly we will not provision for communication between
%  different architectures. 
\item The protocol will be text based, primarily to ease development
  and debugging. It is entirely feasible to later replace this with a
  binary protocol.
\end{itemize}

Our protocol is very compact. The actual implementation may use
different symbols to represent the operators below. We need our
protocol to support the following operators. A description is supplied
for each.

\begin{description}
  \item[\textbar] The end of the channel list is reached and we should
    set the active channel to the first channel. This coincides with
    reading a new character. It is not a strictly necessary operator,
    we can make do with the change channels action. We choose to keep
    a separate action for end of list, because it adds to readability
    and redundancy.
  \item[:] Whenever we change channels we put a :. There may be more
    than one or perhaps even no bits output on a channel for any given
    character from the string
  \item[=] Copying of a channel. One channel is split into two, the
    paths taken through the NFA will be identical up to the point of
    splitting. The newly created channel is put in front of the rest
    of the channels
  \item[0,1] The actual bit values. 
  \item [\textbackslash $a$] The character classes is a special
    case. To later be able to recreate the exact string that we
    matched, we will need to know which character a character class
    matched. To meet this requirement we will output the character we
    matched the character class with in the output. To signal such a
    character is coming we use an escape \textbackslash.
  \item[b] A channel is abandoned with no match
  \item[t] A channel has a match
\end{description}

\begin{example}[Protocol]
  In figure \vref{fig:ex_prot} we have an automaton for regular
  expression \textsf{a*}. When matching this regular expression with
  the string \textsl{aa} we generate some mixed bit-values. This
  example will in detail demonstrate how the mixed bit-values are
  generated.
  \begin{figure}
    \centering
    \includegraphics{matching/example_protocol.pdf}
    \caption{Automaton with bitvalues for regular expression
      \texttt{a*}}
    \label{fig:ex_prot}
  \end{figure}
  
  \begin{description}
  
  \item[Initial step:] Initially the start state of the automaton is
    added to the active list. All $\upvarepsilon$-edges are followed
    and the following is output:
    \begin{enumerate}
    \item Node 1 is a split-node, a \texttt{=} is output, and we
      follow the $\upvarepsilon$-edge to node 2 and output a
      \texttt{0}. We can not make any further progress on this
      channel. We output a \texttt{:} and switch to the next channel.

      Output so far: \texttt{=0:}. \\
      List of active channels: $\{2, 1\}$.
    \item The active channel is now in node 1, we follow the
      $\upvarepsilon$-edge from node 1 to 3 and output a
      \texttt{1}. We can not make any further progress on this
      channel. This is the last channel in the channel list, so we
      output a \texttt{|} and reset the active channel.

      Output so far: \texttt{=0:1|}.\\
      List of active channels: $\{2, 3\}$.
    \end{enumerate}

  \item[First \textsl{a} is read]
    \begin{enumerate}
    \item Node 2 has a transition marked \texttt{a}, we follow this
      back to node 1. Node 1 is a split-node, a \texttt{=} is output,
      and we follow the $\upvarepsilon$-edge to node 2 and output a
      \texttt{0}. We can not make any further progress on this
      channel. We output a \texttt{:} and switch to the next channel.

      Output so far: \texttt{=0:1|=0:}. \\
      List of active channels: $\{2, 1, 3\}$.
    \item The active channel is now in node 1, we follow the
      $\upvarepsilon$-edge from node 1 to 3 and output a
      \texttt{1}. We can not make any further progress on this
      channel. We output a \texttt{:} and switch to the next channel.

      Output so far: \texttt{=0:1|=0:1:}. \\
      List of active channels: $\{2, 3, 3\}$.
    \item Node 3 is the accepting node and does not have any
      transitions. We abandon this channel and output a
      \texttt{b}. This is the last channel in the channel list, so we
      output a \texttt{|} and reset the active channel.

      Output so far: \texttt{=0:1|=0:1:b|}. \\
      List of active channels: $\{2, 3\}$.
    \end{enumerate}
  \item[Second \textsl{a} is read] This is the final step.
    \begin{enumerate}
      \item From node 2 we can make a transition on \texttt{a} back to
        node 1. This is a split node, so we output a \texttt{=} and
        transition on the the $\upvarepsilon$-edge to node 2 and
        output a \texttt{0}. We can not do further transitions and
        this is not the accepting node, we abandon this channel and
        output a \texttt{b}. We switch to the next channel and output
        a \texttt{:}.

        Output so far: \texttt{=0:1|=0:1:b|=0b:}. \\
        List of active channels: $\{1, 3\}$.
      \item Node 1 has a $\upvarepsilon$-transition to node 3, we take
        it and output a \texttt{1}. We can not do further transitions
        and since this is the accepting node, we output a
        \texttt{t}. We have one channel left, so we output a
        \texttt{:} and switch.

        Output so far: \texttt{=0:1|=0:1:b|=0b:1t:}. \\
        List of active channels: $\{3\}$.
      \item Node 3 has no available transitions. We abandon this
        channel and output a \texttt{b}.

        Output so far: \texttt{=0:1|=0:1:b|=0b:1t:b}. \\
        List of active channels: $\{\}$.
    \end{enumerate}
  \end{description}
\end{example}

\input{filters}
